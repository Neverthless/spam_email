{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def lg(num):\n",
    "    if num==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(num)\n",
    "\n",
    "def whichClass(spam, legit):\n",
    "    if legit==0:\n",
    "        return 1 #spam\n",
    "    elif spam/legit>=1:\n",
    "        return 1 #spam\n",
    "    else:\n",
    "        return 0 #legit\n",
    "        \n",
    "# Get all the words from all emails, and separate them by spam and non-spam.\n",
    "\n",
    "p = \"lingspam_public/lemm_stop\"\n",
    "dict_legit = {}\n",
    "dict_spam = {}\n",
    "term_freq = {}\n",
    "spam = 0\n",
    "legit = 0\n",
    "pattern = re.compile(r'([a-z]+)', re.I)\n",
    "for i in range(1,11):\n",
    "    path = p + \"/part\" + str(i)\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        dict_count = {}\n",
    "        txt = open(path +\"/\"+ file).read()\n",
    "        words = pattern.findall(txt)\n",
    "        for word in words:\n",
    "            dict_count[word] = dict_count.get(word, 0)+1\n",
    "            term_freq[word] = term_freq.get(word, 0)+1\n",
    "        for word in dict_count.keys():\n",
    "            if dict_count.get(word, 0) != 0 and file.find(\"spm\")==-1:\n",
    "                dict_legit[word] = dict_legit.get(word, 0) + 1\n",
    "            else:\n",
    "                dict_spam[word] = dict_spam.get(word, 0) + 1\n",
    "word_legit = sorted(dict_legit, key = lambda x: dict_legit[x], reverse = True)\n",
    "word_spam = sorted(dict_spam, key = lambda x: dict_spam[x], reverse = True)\n",
    "word_ = {}.fromkeys(word_legit+word_spam).keys()\n",
    "\n",
    "spam = 481\n",
    "legit = 2412\n",
    "n = 2893\n",
    "H = -(legit/n)*np.log(legit/n)-(spam/n)*np.log(spam/n)\n",
    "class_ = {}\n",
    "\n",
    "ig = {}\n",
    "for word in word_list:\n",
    "    if word==\"Subject\":\n",
    "        continue\n",
    "    N = dict_legit.get(word,0)+dict_spam.get(word,0)\n",
    "    p_spam = dict_spam.get(word,0)/spam\n",
    "    p_legit = dict_legit.get(word,0)/legit\n",
    "    lg_spam = (spam/n)*(p_spam)/(N/n)\n",
    "    \n",
    "    H_ = -(spam/n)*(p_spam)*lg(lg_spam)-(spam/n)*(1-p_spam)*lg((spam/n)*(1-p_spam)/(1-N/n))\\\n",
    "        -(legit/n)*(p_legit)*lg((legit/n)*(p_legit)/(N/n))-(legit/n)*(1-p_legit)*lg((legit/n)*(1-p_legit)/(1-N/n))\n",
    "    ig[word] = H-H_\n",
    "    \n",
    "    class_[word] = whichClass((dict_spam.get(word,0)/spam)*(spam/n),(dict_legit.get(word,0)/legit)*(legit/n))\n",
    "data = sorted(ig, key = lambda x: ig[x], reverse = True)\n",
    "N_10 = data[0:10]\n",
    "print(N_10)\n",
    "N_10 = N_10.reshape(10,1)\n",
    "N_100 = data[0:100]\n",
    "N_100 = N_100.reshape(100,1)\n",
    "N_1000 = data[0:1000]\n",
    "N_1000 = N_1000.reshape(1000,1)\n",
    "class_N_10 = []\n",
    "for word in N_10:\n",
    "    class_N_10.append(class_[word])\n",
    "class_N_100 = []\n",
    "for word in N_100:\n",
    "    class_N_100.append(class_[word])\n",
    "class_N_1000 = []\n",
    "for word in N_1000:\n",
    "    class_N_1000.append(class_[word])\n",
    "    \n",
    "# Bernoulli NB classifier with binary features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def load_emails(path):\n",
    "    texts = []\n",
    "    for entry in os.listdir(path):\n",
    "        is_spam = 0\n",
    "        if entry[0] == 's':\n",
    "            is_spam = 1\n",
    "        with open(os.path.join(path, entry), 'r') as mail:\n",
    "            next(mail)\n",
    "            word_count = {}\n",
    "            words = mail.read().replace('\\n', '').split()\n",
    "            for word in words:\n",
    "                striped = word.strip(string.punctuation)\n",
    "                if striped.isalpha():\n",
    "                    if striped not in word_count:\n",
    "                        word_count[striped] = 1\n",
    "                    else:\n",
    "                        word_count[striped] += 1\n",
    "            texts.append((word_count, is_spam))\n",
    "    return texts\n",
    "\n",
    "\n",
    "def select_feature(data, size):\n",
    "    word_classes = {}\n",
    "    spams = 0\n",
    "    hams = 0\n",
    "    for word_count, is_spam in data:\n",
    "        if is_spam:\n",
    "            spams += 1\n",
    "        else:\n",
    "            hams += 1\n",
    "        for word in word_count:\n",
    "            if word not in word_classes:\n",
    "                word_classes[word] = [0, 0]\n",
    "            word_classes[word][is_spam] += 1\n",
    "    sorted_features = sorted(word_classes,\n",
    "                             key=lambda x: conditional(word_classes[x][1], word_classes[x][0], spams, hams),\n",
    "                             reverse=True)\n",
    "    return sorted_features[0: min(size, len(sorted_features))]\n",
    "\n",
    "\n",
    "def conditional(count_spam, count_ham, spams, hams):\n",
    "    entropy = 0\n",
    "    if count_spam > 0:\n",
    "        entropy += count_spam * np.log(count_spam / (count_spam + count_ham))\n",
    "    if count_ham > 0:\n",
    "        entropy += count_ham * np.log(count_ham / (count_spam + count_ham))\n",
    "    if spams - count_spam > 0:\n",
    "        entropy += (spams - count_spam) * np.log((spams - count_spam) / (spams + hams - count_spam - count_ham))\n",
    "    if hams - count_ham > 0:\n",
    "        entropy += (hams - count_ham) * np.log((hams - count_ham) / (spams + hams - count_spam - count_ham))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def evaluate(eval_model, eval_data):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    for text, is_spam in eval_data:\n",
    "        prediction = eval_model.predict(text)\n",
    "        if is_spam == 1:\n",
    "            if prediction == 1:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_neg += 1\n",
    "        else:\n",
    "            if prediction == 1:\n",
    "                false_pos += 1\n",
    "            else:\n",
    "                true_neg += 1\n",
    "    eval_precision = true_pos / (true_pos + false_pos)\n",
    "    eval_recall = true_pos / (true_pos + false_neg)\n",
    "    false_pos_rate = false_pos / (false_pos + true_neg)\n",
    "    false_neg_rate = false_neg / (true_pos + false_neg)\n",
    "    return eval_precision, eval_recall, false_pos_rate, false_neg_rate\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bernoulli\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Naive Bayes classifier\n",
    "class NB:\n",
    "\n",
    "    def __init__(self, classifier_type):\n",
    "        if classifier_type not in ['Binomial BF', 'Multinomial BF', 'Multinomial TF']:\n",
    "            raise ValueError('Invalid classifier type.')\n",
    "        self.classifier_type = classifier_type\n",
    "        self.spam_prob = {}\n",
    "        self.ham_prob = {}\n",
    "\n",
    "    def fit(self, texts, features):\n",
    "        spam_dict = {}\n",
    "        ham_dict = {}\n",
    "        texts_spam = 0\n",
    "        texts_ham = 0\n",
    "        # Laplace smoothing\n",
    "        for word in features:\n",
    "            spam_dict[word] = 1\n",
    "            ham_dict[word] = 1\n",
    "        for word_count, is_spam in texts:\n",
    "            if is_spam == 1:\n",
    "                texts_spam += 1\n",
    "                for word in word_count:\n",
    "                    if word in spam_dict:\n",
    "                        if self.classifier_type[0] == 'B':\n",
    "                            spam_dict[word] += 1\n",
    "                        elif self.classifier_type[0] == 'M':\n",
    "                            spam_dict[word] += word_count[word]\n",
    "            else:\n",
    "                texts_ham += 1\n",
    "                for word in word_count:\n",
    "                    if word in ham_dict:\n",
    "                        if self.classifier_type[0] == 'B':\n",
    "                            ham_dict[word] += 1\n",
    "                        elif self.classifier_type[0] == 'M':\n",
    "                            ham_dict[word] += word_count[word]\n",
    "        if self.classifier_type[0] == 'B':\n",
    "            spam_count = texts_spam + 2\n",
    "            ham_count = texts_ham + 2\n",
    "        else:\n",
    "            spam_count = sum(spam_dict.values())\n",
    "            ham_count = sum(ham_dict.values())\n",
    "        for word in spam_dict:\n",
    "            self.spam_prob[word] = spam_dict[word] / spam_count\n",
    "        for word in ham_dict:\n",
    "            self.ham_prob[word] = ham_dict[word] / ham_count\n",
    "\n",
    "    def predict(self, text):\n",
    "        # spam_rate is the prior probability that an email is spam, 0.5 by default\n",
    "        predict_spam = 0\n",
    "        predict_ham = 0\n",
    "        # Binomial BF\n",
    "        if self.classifier_type[0] == 'B':\n",
    "            for word in self.spam_prob:\n",
    "                if word in text:\n",
    "                    predict_spam += np.log(self.spam_prob[word])\n",
    "                else:\n",
    "                    predict_spam += np.log(1 - self.spam_prob[word])\n",
    "            for word in self.ham_prob:\n",
    "                if word in text:\n",
    "                    predict_ham += np.log(self.ham_prob[word])\n",
    "                else:\n",
    "                    predict_ham += np.log(1 - self.ham_prob[word])\n",
    "        # Multinomial NB\n",
    "        elif self.classifier_type[0] == 'M':\n",
    "            for word in text:\n",
    "                xi = text[word]\n",
    "                # Multinomial BF\n",
    "                if self.classifier_type[-2] == 'B':\n",
    "                    xi = 1\n",
    "                if word in self.spam_prob:\n",
    "                    predict_spam += xi * np.log(self.spam_prob[word])\n",
    "                if word in self.ham_prob:\n",
    "                    predict_ham += xi * np.log(self.ham_prob[word])\n",
    "        # return 1 if we classify this email as spam and 0 if not\n",
    "        if predict_spam > predict_ham:\n",
    "            return 1\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# svm classifier\n",
    "class SVM:\n",
    "    def __init__(self, kernel):\n",
    "        self.clf = svm.SVC(kernel=kernel)\n",
    "        self.feature_indices = {}\n",
    "\n",
    "    def fit(self, texts, features):\n",
    "        # transform dictionary to vector\n",
    "        self.feature_indices = {features[i]: i for i in range(len(features))}\n",
    "        train_data = np.zeros((len(texts), len(self.feature_indices)))\n",
    "        labels = np.zeros((len(texts),))\n",
    "        for i, (word_count, is_spam) in enumerate(texts):\n",
    "            for word, count in word_count.items():\n",
    "                if word in self.feature_indices:\n",
    "                    train_data[i, self.feature_indices[word]] = count\n",
    "            labels[i] = is_spam\n",
    "        self.clf.fit(train_data, labels)\n",
    "\n",
    "    def predict(self, text):\n",
    "        test_data = np.zeros((1, len(self.feature_indices)))\n",
    "        for word, count in text.items():\n",
    "            if word in self.feature_indices:\n",
    "                test_data[0, self.feature_indices[word]] = count\n",
    "        label = self.clf.predict(test_data)\n",
    "        return int(np.squeeze(label))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adversial\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# the adversary that tries to cheat the NB classifier model by adding words\n",
    "class Attacker:\n",
    "    def __init__(self, model):\n",
    "        if model.classifier_type != 'Multinomial BF':\n",
    "            raise ValueError('Invalid classifier type.')\n",
    "        self.features = []\n",
    "        self.log_odds = []\n",
    "        for word in model.spam_prob:\n",
    "            self.features.append(word)\n",
    "            self.log_odds.append(int((np.log(model.spam_prob[word]) - np.log(model.ham_prob[word])) * 100))\n",
    "\n",
    "    def attack(self, text, max_cost):\n",
    "        one_hot = self.text2vec(text)\n",
    "        cost, add_words = self.get_list(one_hot, max_cost)\n",
    "        if add_words is not None:\n",
    "            for i in add_words:\n",
    "                text[self.features[i - 1]] = 1\n",
    "            return cost\n",
    "        return 0\n",
    "\n",
    "    def get_list(self, one_hot, max_cost):\n",
    "        gap = self.get_gap(one_hot)\n",
    "        add_list = None\n",
    "        cost, add_indices = self.find_mcc(one_hot, len(one_hot), gap)\n",
    "        if gap > 0 and cost <= max_cost:\n",
    "            add_list = add_indices\n",
    "        return cost, add_list\n",
    "\n",
    "    def text2vec(self, text):\n",
    "        one_hot = []\n",
    "        for word in self.features:\n",
    "            if word in text:\n",
    "                one_hot.append(1)\n",
    "            else:\n",
    "                one_hot.append(0)\n",
    "        return one_hot\n",
    "\n",
    "    def get_gap(self, one_hot):\n",
    "        gap = 0\n",
    "        for i, present in enumerate(one_hot):\n",
    "            if present == 1:\n",
    "                gap += self.log_odds[i]\n",
    "        return gap\n",
    "\n",
    "    # find the minimum cost to change the text to non-spam\n",
    "    def find_mcc(self, one_hot, i, gap):\n",
    "        if gap <= 0:\n",
    "            return 0, []\n",
    "        if i == 0:\n",
    "            return np.inf, None\n",
    "        min_cost = np.inf\n",
    "        min_list = None\n",
    "        if one_hot[i - 1] == 0 and self.log_odds[i - 1] < 0:\n",
    "            cur_cost, cur_list = self.find_mcc(one_hot, i - 1, gap + self.log_odds[i - 1])\n",
    "            if cur_cost + 1 < min_cost:\n",
    "                min_cost = cur_cost + 1\n",
    "                min_list = cur_list\n",
    "                min_list.append(i)\n",
    "        else:\n",
    "            cur_cost, cur_list = self.find_mcc(one_hot, i - 1, gap)\n",
    "            if cur_cost < min_cost:\n",
    "                min_cost = cur_cost\n",
    "                min_list = cur_list\n",
    "        return min_cost, min_list\n",
    "\n",
    "\n",
    "class Defender(NB):\n",
    "    def __init__(self):\n",
    "        super(Defender, self).__init__('Multinomial BF')\n",
    "        self.adversary = Attacker(self)\n",
    "\n",
    "    def fit(self, texts, features):\n",
    "        super(Defender, self).fit(texts, features)\n",
    "        self.adversary = Attacker(self)\n",
    "\n",
    "    def predict(self, text):\n",
    "        one_hot = self.adversary.text2vec(text)\n",
    "        originals = self.get_original(one_hot)\n",
    "        ###\n",
    "        spam_prob_vec = list(self.spam_prob.values())\n",
    "        ham_prob_vec = list(self.ham_prob.values())\n",
    "        print(spam_prob_vec)\n",
    "        print(ham_prob_vec)\n",
    "        predict_spam = 0\n",
    "        predict_ham = 0\n",
    "        exp_predict_spam = 0\n",
    "        for i in range(len(one_hot)):\n",
    "            if one_hot[i] == 1:\n",
    "                predict_spam += np.log(spam_prob_vec[i])\n",
    "        for i in range(len(one_hot)):\n",
    "            if one_hot[i] == 1:\n",
    "                predict_ham += np.log(ham_prob_vec[i])\n",
    "        if predict_spam <= predict_ham or len(originals) == 0:\n",
    "            exp_predict_spam += np.exp(predict_spam)\n",
    "        for original in originals:\n",
    "            predict_original = 0\n",
    "            for i in range(len(original)):\n",
    "                if original[i] == 1:\n",
    "                    predict_original += np.log(spam_prob_vec[i])\n",
    "            exp_predict_spam += np.exp(predict_original)\n",
    "        if exp_predict_spam > np.exp(predict_ham):\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def get_original(self, one_hot):\n",
    "        originals = []\n",
    "        for i in range(len(one_hot)):\n",
    "            if one_hot[i] == 1:\n",
    "                one_hot[i] = 0\n",
    "                _, mcc_list = self.adversary.get_list(one_hot, 1)\n",
    "                if mcc_list is not None and mcc_list[0] == i + 1:\n",
    "                    originals.append(one_hot.copy())\n",
    "                one_hot[i] = 1\n",
    "        return originals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lingspam_public/lemm_stop\n",
      "top 10 features: ['language', 'remove', 'free', 'linguistic', 'university', 'money', 'click', 'market', 'our', 'business']\n",
      "                                precision    recall\n",
      "Binomial NB with BF, N=10        0.803571  0.918367\n",
      "Multinomial NB with BF, N=10     0.803571  0.918367\n",
      "Multinomial NB with TF, N=10     0.836364  0.938776\n",
      "Binomial NB with BF, N=100       1.000000  0.755102\n",
      "Multinomial NB with BF, N=100    0.960000  0.979592\n",
      "Multinomial NB with TF, N=100    0.940000  0.959184\n",
      "Binomial NB with BF, N=1000      1.000000  0.612245\n",
      "Multinomial NB with BF, N=1000   1.000000  0.938776\n",
      "Multinomial NB with TF, N=1000   1.000000  0.938776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Precision    Recall\n",
      "Linear SVM, N = 10         0.906977  0.795918\n",
      "RBF kernel SVM, N = 10     0.900000  0.734694\n",
      "Linear SVM, N = 100        0.952381  0.816327\n",
      "RBF kernel SVM, N = 100    0.972222  0.714286\n",
      "Linear SVM, N = 1000       0.807692  0.857143\n",
      "RBF kernel SVM, N = 1000   1.000000  0.591837\n",
      "Before attack:\n",
      "False negative rate of the baseline NB classifier =  0.08163265306122448\n",
      "Attack Launched......\n",
      "Average cost by attacker =  0.3230240549828179\n",
      "After attack:\n",
      "False negative rate of the baseline NB classifier =  0.9591836734693877\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-bedc4be0365e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mupdated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_emails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_fnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_emails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classifier updated......'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'False negative rate of the updated NB classifier = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_fnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-1b956ee531bd>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(eval_model, eval_data)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mfalse_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_spam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_spam\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-ce253f992d1d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moriginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_original\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mspam_prob_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspam_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mham_prob_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mham_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_prob_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load data\n",
    "    base_path = 'lingspam_public/lemm_stop'\n",
    "    print(base_path)\n",
    "    train_emails = []\n",
    "    for i in range(1, 10):\n",
    "        train_emails.extend(load_emails(os.path.join(base_path, 'part' + str(i))))\n",
    "    test_emails = load_emails(os.path.join(base_path, 'part10'))\n",
    "    # top 10 features\n",
    "    top_10 = select_feature(train_emails, 10)\n",
    "    print('top 10 features:', top_10)\n",
    "\n",
    "    # create naive bayes models\n",
    "    nb_models = {\n",
    "        'Binomial NB with BF': NB('Binomial BF'),\n",
    "        'Multinomial NB with BF': NB('Multinomial BF'),\n",
    "        'Multinomial NB with TF': NB('Multinomial TF')\n",
    "    }\n",
    "    # train ans test models\n",
    "    nb_results = {}\n",
    "    for feature_size in [10, 100, 1000]:\n",
    "        for model_name, model in nb_models.items():\n",
    "            # select features\n",
    "            features = select_feature(train_emails, feature_size)\n",
    "            model.fit(train_emails, features)\n",
    "            precision, recall, _, _ = evaluate(model, test_emails)\n",
    "            nb_results[model_name + ', N=' + str(feature_size)] = [precision, recall]\n",
    "    nb_results_df = pd.DataFrame(nb_results, index=['precision', 'recall']).T\n",
    "    # print results\n",
    "    print(nb_results_df)\n",
    "\n",
    "    # create svm models\n",
    "    svm_models = {\n",
    "        'Linear SVM': SVM('linear'),\n",
    "        'RBF kernel SVM': SVM('rbf')\n",
    "    }\n",
    "    # train ans test models\n",
    "    svm_results = {}\n",
    "    for feature_size in [10, 100, 1000]:\n",
    "        for model_name, model in svm_models.items():\n",
    "            # select features\n",
    "            features = select_feature(train_emails, feature_size)\n",
    "            model.fit(train_emails, features)\n",
    "            precision, recall, _, _ = evaluate(model, test_emails)\n",
    "            svm_results[model_name + ', N = ' + str(feature_size)] = [precision, recall]\n",
    "    svm_results_df = pd.DataFrame(svm_results, index=['Precision', 'Recall']).T\n",
    "    # print results\n",
    "    print(svm_results_df)\n",
    "\n",
    "    # adversarial test\n",
    "    baseline = NB('Multinomial BF')\n",
    "    baseline.fit(train_emails, top_10)\n",
    "    _, _, _, base_bnr_before = evaluate(baseline, test_emails)\n",
    "    print('Before attack:')\n",
    "    print('False negative rate of the baseline NB classifier = ', base_bnr_before)\n",
    "    # attack launched\n",
    "    attacker = Attacker(baseline)\n",
    "    total_cost = 0\n",
    "    for email, _ in test_emails:\n",
    "        total_cost += attacker.attack(email, 10)\n",
    "    print('Attack Launched......')\n",
    "    print('Average cost by attacker = ', total_cost / len(test_emails))\n",
    "    _, _, _, base_fnr_after = evaluate(baseline, test_emails)\n",
    "    print('After attack:')\n",
    "    print('False negative rate of the baseline NB classifier = ', base_fnr_after)\n",
    "    # update the classifier to defend the attack\n",
    "    updated = Defender()\n",
    "    updated.fit(train_emails, top_10)\n",
    "    _, _, updated_fpr, updated_fnr = evaluate(updated, test_emails)\n",
    "    print('Classifier updated......')\n",
    "    print('False negative rate of the updated NB classifier = ', updated_fnr)\n",
    "    print('False positive rate of the updated NB classifier = ', updated_fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
